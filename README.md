# ufg_solar
RepositÃ³rio do Projeto de FinalizaÃ§Ã£o de Curso do curso de Engenharia de ComputaÃ§Ã£o na Universidade Federal de GoiÃ¡s

## VisÃ£o Geral da Arquitetura

O projeto Ã© dividido em camadas lÃ³gicas, cada uma contida em seu prÃ³prio diretÃ³rio:
- **`credenciais`**: Gerencia o acesso seguro a bancos de dados e APIs.
- **`bancos`** e **`apis`**: Camadas de baixo nÃ­vel responsÃ¡veis pela comunicaÃ§Ã£o com as fontes de dados (internas e externas).
- **`extratores`**: Camada de orquestraÃ§Ã£o e lÃ³gica de negÃ³cio, que utiliza os outros componentes para executar o pipeline completo.

---

### ğŸ“ `credenciais/`
Esta pasta centraliza todas as informaÃ§Ãµes sensÃ­veis e a lÃ³gica para carregÃ¡-las, garantindo que o cÃ³digo-fonte permaneÃ§a livre de senhas ou chaves de API.

- **ğŸ“„ `credenciais_apis.xlsx`** e **ğŸ“„ `credenciais_bancos.xlsx`**: Planilhas Excel que armazenam as credenciais de acesso para as APIs externas (Solis, WEG, Solarman) e para os bancos de dados (Supabase, SideUFG), respectivamente. **Esses arquivos nunca devem ser enviados para o GitHub e devem estar no seu arquivo `.gitignore`**.
- **ğŸ“„ `gerenciador_credenciais.py`**: MÃ³dulo responsÃ¡vel por ler as planilhas `.xlsx` e carregar as credenciais de forma segura em dicionÃ¡rios Python. Esses dicionÃ¡rios sÃ£o importados e utilizados pelos mÃ³dulos das pastas `bancos` e `apis`.

### ğŸ“ `bancos/`
ContÃ©m os "clientes" de banco de dados. Cada mÃ³dulo aqui Ã© um especialista em se comunicar com um banco de dados especÃ­fico.

- **ğŸ“„ `funcs_supabase.py`**: Centraliza toda a comunicaÃ§Ã£o com o banco de dados Supabase. Ele gerencia uma conexÃ£o de cliente Ãºnica e eficiente e fornece funÃ§Ãµes genÃ©ricas para realizar consultas (`consultar_supabase`) e buscar valores especÃ­ficos (`obter_valor_maximo_coluna`).
- **ğŸ“„ `funcs_sideufg.py`**: ResponsÃ¡vel por toda a comunicaÃ§Ã£o com o banco de dados PostgreSQL (SideUFG), fornecendo uma funÃ§Ã£o genÃ©rica para executar consultas SQL.

### ğŸ“ `apis/`
Similar Ã  pasta `bancos`, esta contÃ©m os clientes para as APIs externas. Cada mÃ³dulo encapsula a complexidade de autenticaÃ§Ã£o e chamada de endpoints de uma plataforma.

- **ğŸ“„ `funcs_solis.py`**: ContÃ©m toda a lÃ³gica para interagir com a API da Solis, incluindo a complexa geraÃ§Ã£o de cabeÃ§alhos de autenticaÃ§Ã£o e a iteraÃ§Ã£o diÃ¡ria para busca de dados histÃ³ricos.
- **ğŸ“„ `funcs_weg.py`**: ResponsÃ¡vel por se comunicar com a API da WEG, ajustando os parÃ¢metros de data/hora para o fuso horÃ¡rio correto (UTC-3) e realizando a busca de dados dia a dia.
- **ğŸ“„ `funcs_solarman.py`**: Gerencia a comunicaÃ§Ã£o com a API da Solarman, incluindo o processo de obtenÃ§Ã£o e atualizaÃ§Ã£o de tokens de acesso e a busca de dados histÃ³ricos por dia.

### ğŸ“ `extratores/`
O coraÃ§Ã£o do projeto, onde a orquestraÃ§Ã£o acontece. Este diretÃ³rio contÃ©m os pipelines de alto nÃ­vel e seus componentes.

#### ğŸ“ `extratores/parametros/`
MÃ³dulos responsÃ¡veis por gerar dinamicamente os parÃ¢metros necessÃ¡rios para cada execuÃ§Ã£o.

- **ğŸ“„ `parametros_inversores.py`**: Consulta o banco Supabase para obter a lista de inversores de cada plataforma. Ele gera uma estrutura de dados que contÃ©m tanto o nÃºmero de sÃ©rie original do inversor (`sn_original`) quanto o identificador formatado para a API (`id_formatado`).
- **ğŸ“„ `parametros_datas.py`**: Calcula o intervalo de tempo correto para cada extraÃ§Ã£o. Para cada inversor, ele busca a data da Ãºltima leitura no Supabase para definir a `data_inicio` e usa a data/hora atual para a `data_fim`. TambÃ©m contÃ©m a lÃ³gica para ajustar o fuso horÃ¡rio da Solis.

#### ğŸ“ `extratores/tratamento/`
MÃ³dulos responsÃ¡veis por transformar os dados brutos extraÃ­dos em formatos padronizados, prontos para serem carregados no banco de dados.

- **ğŸ“„ `tratamento_solis.py`**, **ğŸ“„ `tratamento_weg.py`**, **ğŸ“„ `tratamento_solarman.py`**: Cada um desses arquivos contÃ©m uma funÃ§Ã£o que recebe um DataFrame de dados brutos de sua respectiva plataforma e retorna dois DataFrames:
    1.  **Completo**: ContÃ©m todos os dados originais, com colunas renomeadas e um ID Ãºnico, pronto para uma tabela de log detalhada.
    2.  **Resumido**: ContÃ©m apenas as colunas essenciais (`data_hora`, `inversor_sn`, `potencia_kw`, etc.), padronizadas para serem inseridas na tabela principal `leitura`.

#### Arquivos Principais

- **ğŸ“„ `extrator_sideufg.py`**, **ğŸ“„ `extrator_solis.py`**, **ğŸ“„ `extrator_weg.py`**, **ğŸ“„ `extrator_solarman.py`**: SÃ£o os scripts de pipeline individuais para cada fonte de dados. O fluxo de cada um Ã©:
    1.  Chamar os mÃ³dulos de `parametros` para obter a lista de inversores e os intervalos de data.
    2.  Chamar o mÃ³dulo `apis` ou `bancos` correspondente para extrair os dados brutos.
    3.  Chamar o mÃ³dulo `tratamento` correspondente para processar os dados.
    4.  Salvar os dois DataFrames resultantes em arquivos CSV na pasta `resultados`.

- **ğŸ“„ `teste_extratores.py`**: O script mestre do projeto. Ele serve como ponto de entrada para executar todo o processo de ETL em sequÃªncia. Ele importa e chama a funÃ§Ã£o principal de cada um dos scripts extratores, orquestrando a extraÃ§Ã£o completa de todas as fontes.

#### ğŸ“ `extratores/resultados/`
Esta pasta Ã© criada automaticamente pelo `teste_extratores.py` e Ã© para onde todos os arquivos CSV de resultado sÃ£o salvos. Ela serve como um "armazÃ©m temporÃ¡rio" dos dados tratados, validando que todo o processo de extraÃ§Ã£o e tratamento funcionou corretamente antes da futura implementaÃ§Ã£o do carregamento para o banco.
